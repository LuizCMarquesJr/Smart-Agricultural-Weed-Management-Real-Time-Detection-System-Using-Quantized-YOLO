{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# 03. Quantization and Export\n",
                "\n",
                "This notebook demonstrates how to export YOLOv5 models to ONNX and apply Quantization (FP16, INT8).\n",
                "\n",
                "## Objectives\n",
                "1. Export to ONNX.\n",
                "2. Apply FP16 Quantization.\n",
                "3. Apply INT8 Post-Training Quantization (PTQ).\n",
                "\n",
                "**Note**: Ensure you are in the `yolov5` directory or have it in your python path."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Setup\n",
                "import os\n",
                "if os.path.basename(os.getcwd()) != 'yolov5':\n",
                "    %cd yolov5\n",
                "    \n",
                "import onnx\n",
                "from onnxruntime.quantization import quantize_dynamic, quantize_static, CalibrationDataReader, QuantType\n",
                "import cv2\n",
                "import numpy as np\n",
                "import glob"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1. Export to ONNX (Base)\n",
                "We export the trained model (e.g., `runs/train/exp/weights/best.pt`) or a pretrained one."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Export to ONNX\n",
                "!python export.py --weights yolov5n.pt --include onnx --opset 12"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2. FP16 Quantization\n",
                "YOLOv5's export script can often handle FP16 export directly (using `--half` if on GPU), or modern inference runtimes handle it. For explicit ONNX FP16 conversion:"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from onnxconverter_common import float16\n",
                "\n",
                "model_fp32 = 'yolov5n.onnx'\n",
                "model_fp16 = 'yolov5n_fp16.onnx'\n",
                "\n",
                "model = onnx.load(model_fp32)\n",
                "model_fp16_onnx = float16.convert_float_to_float16(model)\n",
                "onnx.save(model_fp16_onnx, model_fp16)\n",
                "print(f\"Exported {model_fp16}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3. INT8 Quantization (Post-Training)\n",
                "For INT8, we need a calibration dataset (representative of real data) to calculate dynamic ranges.\n",
                "\n",
                "### Calibration Data Reader"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "class YOLODataReader(CalibrationDataReader):\n",
                "    def __init__(self, image_folder, input_name='images', size=(640, 640)):\n",
                "        self.image_folder = image_folder\n",
                "        self.image_paths = glob.glob(os.path.join(image_folder, '*.jpg'))[:50] # Use 50 samples\n",
                "        self.input_name = input_name\n",
                "        self.size = size\n",
                "        self.enum_data = iter(self.image_paths)\n",
                "\n",
                "    def get_next(self):\n",
                "        try:\n",
                "            image_path = next(self.enum_data)\n",
                "            img = cv2.imread(image_path)\n",
                "            img = cv2.resize(img, self.size)\n",
                "            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
                "            img = img.astype('float32') / 255.0\n",
                "            img = img.transpose(2, 0, 1) # HWC to CHW\n",
                "            img = np.expand_dims(img, axis=0)\n",
                "            return {self.input_name: img}\n",
                "        except StopIteration:\n",
                "            return None\n",
                "\n",
                "# Define Dataset path (ensure you have images here from notebook 01)\n",
                "train_images = '../data/datasets/4weed/images/train'\n",
                "if not os.path.exists(train_images):\n",
                "    print(\"Warning: Calibration dataset not found. Please run Notebook 01 first.\")\n",
                "else:\n",
                "    dr = YOLODataReader(train_images)\n",
                "    \n",
                "    # Quantize\n",
                "    quantize_static(\n",
                "        model_input='yolov5n.onnx',\n",
                "        model_output='yolov5n_int8.onnx',\n",
                "        calibration_data_reader=dr,\n",
                "        quant_format=QuantType.QDQ,\n",
                "        weight_type=QuantType.QInt8\n",
                "    )\n",
                "    print(\"Exported yolov5n_int8.onnx\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 4. Compare Size\n",
                "Check the file size reduction."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def get_size(file_path):\n",
                "    size = os.path.getsize(file_path)\n",
                "    return size / (1024 * 1024)\n",
                "\n",
                "print(f\"FP32: {get_size('yolov5n.onnx'):.2f} MB\")\n",
                "print(f\"FP16: {get_size('yolov5n_fp16.onnx'):.2f} MB\")\n",
                "if os.path.exists('yolov5n_int8.onnx'):\n",
                "    print(f\"INT8: {get_size('yolov5n_int8.onnx'):.2f} MB\")"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.8.10"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}