{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 01. Dataset Preparation\n",
    "\n",
    "This notebook handles the downloading and preparation of the **4Weed Dataset** for YOLOv5 training.\n",
    "\n",
    "## Objectives\n",
    "1. Download the dataset from OSF.\n",
    "2. Organize the data into the structure required by YOLOv5.\n",
    "3. Split the data into Training and Validation sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install osfclient pandas sklearn tqdm matplotlib opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm\n",
    "import glob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Download Dataset\n",
    "We use `osfclient` to download the dataset from [OSF 4Weed Project](https://osf.io/w9v3j/).\n",
    "\n",
    "**Note**: If the automated download fails due to authentication or API changes, please download the `4Weed Dataset` zip manually from the link above and place it in the `data/` directory or extract it so that the folders `cocklebur`, `foxtail`, etc. are available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create data directory\n",
    "os.makedirs('data', exist_ok=True)\n",
    "\n",
    "# Attempt to download using osfclient cli\n",
    "# Project ID: w9v3j\n",
    "print(\"Downloading dataset... this make take a while.\")\n",
    "!osf -p w9v3j clone data/raw_download\n",
    "\n",
    "print(\"Download complete (or check for errors above).\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Organize Structure\n",
    "\n",
    "We need to organize the files into:\n",
    "```\n",
    "datasets/4weed/\n",
    "├── images/\n",
    "│   ├── train/\n",
    "│   └── val/\n",
    "└── labels/\n",
    "    ├── train/\n",
    "    └── val/\n",
    "```\n",
    "\n",
    "The 4Weed dataset typically comes with images in folders by class. YOLOv5 requires labels in `.txt` format. \n",
    "**Important**: The 4Weed dataset (from the paper description) seems to ideally have bounding box annotations. If the downloaded dataset only contains images (classification structure), we would need to annotate them. \n",
    "\n",
    "*However, usually such datasets for detection come with XML (Pascal VOC) or txt (YOLO) labels. This script assumes we either have labels or we are setting up the structure for them. Based on the OSF preview, if it's just folders of images, we might be strictly strictly limited unless the annotations are in a separate file or these are crops suitable for classification (which YOLOv5 can also classify with the classification head, but the paper discusses detection).*\n",
    "\n",
    "*Assumption for this script*: We will structure the images. If `txt` labels are found, we move them. If `xml` are found, we convert them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define paths\n",
    "BASE_DIR = 'datasets/4weed'\n",
    "IMG_DIR = os.path.join(BASE_DIR, 'images')\n",
    "LBL_DIR = os.path.join(BASE_DIR, 'labels')\n",
    "\n",
    "for split in ['train', 'val']:\n",
    "    os.makedirs(os.path.join(IMG_DIR, split), exist_ok=True)\n",
    "    os.makedirs(os.path.join(LBL_DIR, split), exist_ok=True)\n",
    "\n",
    "# Classes map\n",
    "CLASSES = ['cocklebur', 'foxtail', 'pigweed', 'ragweed']\n",
    "class_to_id = {cls: i for i, cls in enumerate(CLASSES)}\n",
    "\n",
    "print(\"Directories created.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Data Splitting and Move\n",
    "\n",
    "We will look for images in `data/raw_download/osfstorage` or wherever `osfclient` downloaded them. We'll search recursively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find all images\n",
    "search_path = 'data/raw_download'\n",
    "all_images = []\n",
    "image_extensions = ['.jpg', '.jpeg', '.png', '.bmp']\n",
    "\n",
    "for root, dirs, files in os.walk(search_path):\n",
    "    for file in files:\n",
    "        if any(file.lower().endswith(ext) for ext in image_extensions):\n",
    "            all_images.append(os.path.join(root, file))\n",
    "\n",
    "print(f\"Found {len(all_images)} images.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into Train (80%) and Val (20%)\n",
    "train_imgs, val_imgs = train_test_split(all_images, test_size=0.2, random_state=42)\n",
    "\n",
    "def move_files(file_list, split):\n",
    "    for src_path in tqdm(file_list, desc=f\"Moving {split} files\"):\n",
    "        filename = os.path.basename(src_path)\n",
    "        dst_img_path = os.path.join(IMG_DIR, split, filename)\n",
    "        \n",
    "        # Copy image\n",
    "        shutil.copy(src_path, dst_img_path)\n",
    "        \n",
    "        # Check for corresponding label (assuming .txt same name)\n",
    "        # Note: If labels are XML, we would need a conversion step here.\n",
    "        src_lbl_path = os.path.splitext(src_path)[0] + '.txt'\n",
    "        if os.path.exists(src_lbl_path):\n",
    "            dst_lbl_path = os.path.join(LBL_DIR, split, os.path.basename(src_lbl_path))\n",
    "            shutil.copy(src_lbl_path, dst_lbl_path)\n",
    "\n",
    "move_files(train_imgs, 'train')\n",
    "move_files(val_imgs, 'val')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Verification\n",
    "Check count of files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Train images:\", len(os.listdir(os.path.join(IMG_DIR, 'train'))))\n",
    "print(\"Val images:\", len(os.listdir(os.path.join(IMG_DIR, 'val'))))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
